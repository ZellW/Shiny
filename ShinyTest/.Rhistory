for (i in 1:length(labels))
results[i, labels[[i]] + 1] <- 1
results
}
one_hot_train_labels <- to_one_hot(train_labels)
one_hot_test_labels <- to_one_hot(test_labels)
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels
y_test <- as.numeric(test_labels)
View(one_hot_test_labels)
x_train[1:10]
head(test_labels)
class(test_labels)
class(one_hot_test_labels)
class(one_hot_test_labels[1])
one_hot_test_labels[1:10]
one_hot_test_labels[1:100]
table(one_hot_test_labels)
dim(one_hot_test_labels)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
val_indices <- 1:1000
x_val <- x_train[val_indices,]
partial_x_train <- x_train[-val_indices,]
y_val <- one_hot_train_labels[val_indices,]
partial_y_train = one_hot_train_labels[-val_indices,]
history <- model %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512, validation_data = list(x_val, y_val))
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(optimizer = "rmsprop", loss = "categorical_crossentropy", metrics = c("accuracy"))
history <- model %>% fit(partial_x_train, partial_y_train, epochs = 9, batch_size = 512, validation_data = list(x_val, y_val))
results <- model %>% evaluate(x_test, one_hot_test_labels)
results
test_labels_copy <- test_labels
test_labels_copy <- sample(test_labels_copy)
length(which(test_labels == test_labels_copy)) / length(test_labels)
predictions <- model %>% predict(x_test)
dim(predictions)
sum(predictions[1,])
which.max(predictions[1,])
model %>% compile(optimizer = "rmsprop", loss = "sparse_categorical_crossentropy", metrics = c("accuracy"))
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", prompt = TRUE)
setwd("~/GitHub/MachineLearning")
library(keras)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "keras", prompt = TRUE)
setwd("~/GitHub/MachineLearning")
knitr::include_graphics("./images/network_size1.JPG")
reticulate::repl_python()
import tensorflow as tf
import pandas as pd
import numpy as np
s = pd.Series{[1,3,5,np.nan, 6, 8]}
s = pd.Series([1,3,5,np.nan, 6, 8])
print(s)
dates = pd.date_range('20130101', periods = 6)
print(dates)
import tensorflow as tf
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber",   prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.rar")
#load data with the farff package
data <- readARFF(data_file)
packages("tidyverse", "farff",  "missForest", "dummies", "caret", "lime", prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.rar")
#load data with the farff package
data <- readARFF(data_file)
data_file <- file.path("Chronic_Kidney_Disease.rar")
#load data with the farff package
data <- readARFF(data_file)
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
packages("tidyverse", "farff",  "missForest", "dummies", "caret", "lime", prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
data_imp <- missForest(data)
data_imp_final <- data_imp$ximp
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min),
scale = apply(data_dummy, 2, max)))
# training and test set
set.seed(42)
index <- createDataPartition(data$class, p = 0.9, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
# modeling
model_rf <- caret::train(class ~ .,
data = train_data,
method = "rf", # random forest
trControl = trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
verboseIter = FALSE))
model_rf
# predictions
pred <- data.frame(sample_id = 1:nrow(test_data), predict(model_rf, test_data, type = "prob"), actual = test_data$class) %>%
mutate(prediction = colnames(.)[2:3][apply(.[, 2:3], 1, which.max)], correct = ifelse(actual == prediction, "correct", "wrong"))
confusionMatrix(pred$actual, pred$prediction)
train_x <- dplyr::select(train_data, -class)
test_x <- dplyr::select(test_data, -class)
train_y <- dplyr::select(train_data, class)
test_y <- dplyr::select(test_data, class)
explainer <- lime(train_x, model_rf, n_bins = 5, quantile_bins = TRUE)
explanation_df <- lime::explain(test_x, explainer, n_labels = 1, n_features = 8, n_permutations = 1000, feature_select = "forward_selection")
explanation_df %>%  ggplot(aes(x = model_r2, fill = label)) +  geom_density(alpha = 0.5)
plot_features(explanation_df[1:24, ], ncol = 1)
confusionMatrix(pred$actual, pred$prediction)
pred$actual
pred$prediction
pred$actual
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
data_imp <- missForest(data, verbose = FALSE)
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber",   prompt = FALSE)
# For details related to this data set please refer to
#https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
col.names <- c(
'Status of existing checking account', 'Duration in month', 'Credit history'
, 'Purpose', 'Credit amount', 'Savings account/bonds'
, 'Employment years', 'Installment rate in percentage of disposable income'
, 'Personal status and sex', 'Other debtors / guarantors', 'Present residence since'
, 'Property', 'Age in years', 'Other installment plans', 'Housing', 'Number of existing credits at this bank'
, 'Job', 'Number of people being liable to provide maintenance for', 'Telephone', 'Foreign worker', 'Status'
)
# Get the data
data <- read.csv(url, header=FALSE, sep=' ', col.names=col.names)
# Build a tree
# I already figured these significant variables from my first iteration (not shown in this code for simplicity)
decision.tree <- rpart(
Status ~ Status.of.existing.checking.account + Duration.in.month + Credit.history + Savings.account.bonds,
method="class", data=data)
prp(decision.tree, extra=1, varlen=0, faclen=0, main="Decision Tree for German Credit Data")
new.data <- list(Status.of.existing.checking.account='A11', Duration.in.month=20, Credit.history='A32', Savings.account.bonds='A65')
predict(decision.tree, new.data)
save(decision.tree, file = 'Decision_Tree_German_Credit.RData')
library(plumber)
r <- plumb("my_API.R")
r$run(port=8000)
```{r message=FALSE, warning=FALSE}
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
data_imp <- missForest(data, verbose = FALSE)
data_imp_final <- data_imp$ximp
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min),
scale = apply(data_dummy, 2, max)))
# training and test set
set.seed(42)
index <- createDataPartition(data$class, p = 0.9, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
# modeling
model_rf <- caret::train(class ~ ., data = train_data, method = "rf", # random forest
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = FALSE))
model_rf
# predictions
pred <- data.frame(sample_id = 1:nrow(test_data), predict(model_rf, test_data, type = "prob"), actual = test_data$class) %>%
mutate(prediction = colnames(.)[2:3][apply(.[, 2:3], 1, which.max)], correct = ifelse(actual == prediction, "correct", "wrong"))
confusionMatrix(pred$actual, pred$prediction)
nrow(test_data)
nrow(pred$actual)
pred <- data.frame(sample_id = 1:nrow(test_data), predict(model_rf, test_data, type = "prob"), actual = test_data$class)
View(pred)
mutate(pred, prediction = colnames(.)[2:3][apply(.[, 2:3], 1, which.max)], correct = ifelse(actual == prediction, "correct", "wrong"))
pred <- pred %>% mutate(prediction = colnames(.)[2:3][apply(.[, 2:3], 1, which.max)], correct = ifelse(actual == prediction, "correct", "wrong"))
pred <- data.frame(sample_id = 1:nrow(test_data), predict(model_rf, test_data, type = "prob"), actual = test_data$class)
pred2 <- pred %>% mutate(prediction = colnames(.)[2:3][apply(.[, 2:3], 1, which.max)], correct = ifelse(actual == prediction, "correct", "wrong"))
View(pred2)
confusionMatrix(pred$actual, pred$prediction)
class(pred$actual)
class(pred$prediction)
class(pred2$prediction)
confusionMatrix(pred$actual, as.factor(pred$prediction))
levels(pred$actual)
levels(pred2$prediction)
pred3 <- as.factor(pred2$prediction)
pred3
pred3 <- pred2$prediction %>% as.factor(pred2$prediction)
pred2$prediction <- as.factor(pred2$prediction)
levels(pred2$prediction)
levels(pred$actual)
confusionMatrix(pred2$actual, pred2$prediction)
# take first test case for prediction
input_data <- test_data[1, ] %>%  select(-class)
# predict test case using model
pred <- predict(model_rf, input_data)
cat("----------------\nTest case predicted to be", as.character(pred), "\n----------------")
var_names <- model_rf$finalModel$xNames
var_names
install.packages("rjson")
# show parameter definition for the first three features
for (i in 1:3) {
# if you wanted to see it for all features, use
#for (i in 1:length(var_names)) {
var <- var_names[i]
train_data_subs <- train_data[, which(colnames(train_data) == var)]
type <- class(train_data_subs)
if (type == "numeric") {
min <- min(train_data_subs)
max <- max(train_data_subs)
}
cat("Variable:", var, "is of type:", type, "\n",
"Min value in training data =", min, "\n",
"Max value in training data =", max, "\n----------\n")
}
library(rjson)
test_case_json <- toJSON(input_data)
cat(test_case_json)
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber",   prompt = FALSE)
packages("farff",  "missForest", "dummies", "caret", "lime", prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
data_imp <- missForest(data, verbose = FALSE)
data_imp
View(data_imp)
data_imp_final <- data_imp$ximp
View(data_imp_final)
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
View(data_dummy)
dplyr::select(data_imp_final, class)
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min), scale = apply(data_dummy, 2, max)))
View(data)
data_imp_final <- data_imp$ximp
apply(data_dummy, 2, min)
apply(data_dummy, 2, max)
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min), scale = apply(data_dummy, 2, max)))
# training and test set
set.seed(42)
index <- createDataPartition(data$class, p = 0.9, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
# modeling
model_rf <- caret::train(class ~ ., data = train_data, method = "rf", # random forest
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = FALSE))
model_rf
plot_features(explanation_df[1:24, ], ncol = 1)
# take first test case for prediction
input_data <- test_data[1, ] %>%  select(-class)
# predict test case using model
pred <- predict(model_rf, input_data)
cat("----------------\nTest case predicted to be", as.character(pred), "\n----------------")
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber",   prompt = FALSE)
packages("farff",  "missForest", "dummies", "caret", "lime", prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
glimpse(data)
library(funModeling)
df_status(data)
data_imp <- missForest(data, verbose = FALSE)
data_imp_final <- data_imp$ximp
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min), scale = apply(data_dummy, 2, max)))
glimpse(data)
# training and test set
set.seed(42)
index <- createDataPartition(data$class, p = 0.9, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
# modeling
model_rf <- caret::train(class ~ ., data = train_data, method = "rf", # random forest
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = FALSE))
model_rf
# take first test case for prediction
input_data <- test_data[1, ] %>%  select(-class)
# predict test case using model
pred <- predict(model_rf, input_data)
cat("----------------\nTest case predicted to be", as.character(pred), "\n----------------")
save.image("API2.RData")
# take first test case for prediction
input_data <- test_data[1, ] %>%  select(-class)
# predict test case using model
pred <- predict(model_rf, input_data)
cat("----------------\nTest case predicted to be", as.character(pred), "\n----------------")
var_names <- model_rf$finalModel$xNames
var_names
# show parameter definition for the first three features
for (i in 1:3) {
# if you wanted to see it for all features, use
#for (i in 1:length(var_names)) {
var <- var_names[i]
train_data_subs <- train_data[, which(colnames(train_data) == var)]
type <- class(train_data_subs)
if (type == "numeric") {
min <- min(train_data_subs)
max <- max(train_data_subs)}
cat("Variable:", var, "is of type:", type, "\n",
"Min value in training data =", min, "\n",
"Max value in training data =", max, "\n----------\n")}
library(rjson)
test_case_json <- toJSON(input_data)
cat(test_case_json)
test_case_json <- toJSON(input_data)
cat(test_case_json)
library(plumber)
r <- plumb("My_API.R")
r$run(port = 8000)
library(plumber)
r <- plumb("My_API.R")
#r$run(port = 8000)
r$run(host="127.0.0.1", port=8000, swagger=TRUE)
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber", prompt = FALSE)
packages("farff",  "missForest", "dummies", "caret", "lime",
"funModeling",  "json", prompt = FALSE)
data_file <- file.path("Chronic_Kidney_Disease.arff")
#load data with the farff package
data <- readARFF(data_file)
df_status(data)
data_imp <- missForest(data, verbose = FALSE)
data_imp_final <- data_imp$ximp
data_dummy <- dummy.data.frame(dplyr::select(data_imp_final, -class), sep = "_")
data <- cbind(dplyr::select(data_imp_final, class), scale(data_dummy, center = apply(data_dummy, 2, min), scale = apply(data_dummy, 2, max)))
glimpse(data)
# training and test set
set.seed(42)
index <- createDataPartition(data$class, p = 0.9, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
# modeling
model_rf <- caret::train(class ~ ., data = train_data, method = "rf", # random forest
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = FALSE))
model_rf
load("API2.RData")
# take first test case for prediction
input_data <- test_data[1, ] %>%  select(-class)
# predict test case using model
pred <- predict(model_rf, input_data)
cat("----------------\nTest case predicted to be", as.character(pred), "\n----------------")
var_names <- model_rf$finalModel$xNames
var_names
# show parameter definition for the first three features
for (i in 1:3) {
# if you wanted to see it for all features, use
#for (i in 1:length(var_names)) {
var <- var_names[i]
train_data_subs <- train_data[, which(colnames(train_data) == var)]
type <- class(train_data_subs)
if (type == "numeric") {
min <- min(train_data_subs)
max <- max(train_data_subs)}
cat("Variable:", var, "is of type:", type, "\n",
"Min value in training data =", min, "\n",
"Max value in training data =", max, "\n----------\n")}
test_case_json <- toJSON(input_data)
cat(test_case_json)
library(plumber)
r <- plumb("My_API2.R")
r$run(port = 8000)
library(plumber)
r <- plumb("My_API2.R")
r$run(port = 8000)
setwd("~/GitHub/R_Programming/API_Testing")
# options
options(echo=TRUE)
options(stringsAsFactors=FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("tidyverse", "rpart",  "rpart.plot", "jsonlite", "plumber", prompt = FALSE)
if(!require(easypackages)){install.packages("easypackages")}
library(easypackages)
packages("profvis", "shiny", prompt = FALSE)
setwd("~/GitHub/Shiny/ShinyTest")
library(profvis)
# Generate data
times <- 4e5
cols <- 150
data <- as.data.frame(x = matrix(rnorm(times * cols, mean = 5), ncol = cols))
data <- cbind(id = paste0("g", seq_len(times)), data)
profvis({
data1 <- data   # Store in another variable for this run
# Get column means
means <- apply(data1[, names(data1) != "id"], 2, mean)
# Subtract mean from each column
for (i in seq_along(means)) {
data1[, names(data1) != "id"][, i] <- data1[, names(data1) != "id"][, i] - means[i]
}
}, height = "400px")
profvis({
data1 <- data
# Four different ways of getting column means
means <- apply(data1[, names(data1) != "id"], 2, mean)
means <- colMeans(data1[, names(data1) != "id"])
means <- lapply(data1[, names(data1) != "id"], mean)
means <- vapply(data1[, names(data1) != "id"], mean, numeric(1))
})
profvis({
data1 <- data
means <- vapply(data1[, names(data1) != "id"], mean, numeric(1))
for (i in seq_along(means)) {
data1[, names(data1) != "id"][, i] <- data1[, names(data1) != "id"][, i] - means[i]
}
})
profvis({
data1 <- data
# Given a column, normalize values and return them
col_norm <- function(col) {
col - mean(col)
}
# Apply the normalizer function over all columns except id
data1[, names(data1) != "id"] <- lapply(data1[, names(data1) != "id"], col_norm)
})
profvis({
data <- data.frame(value = runif(5e4))
data$sum[1] <- data$value[1]
for (i in seq(2, nrow(data))) {
data$sum[i] <- data$sum[i-1] + data$value[i]
}
})
profvis({
csum <- function(x) {
if (length(x) < 2) return(x)
sum <- x[1]
for (i in seq(2, length(x))) {
sum[i] <- sum[i-1] + x[i]
}
sum
}
data$sum <- csum(data$value)
})
profvis({
data <- data.frame(value = runif(5e4))
data$sum[1] <- data$value[1]
for (i in seq(2, nrow(data))) {
data$sum[i] <- data$sum[i-1] + data$value[i]
}
})
profvis({
csum <- function(x) {
if (length(x) < 2) return(x)
sum <- x[1]
for (i in seq(2, length(x))) {
sum[i] <- sum[i-1] + x[i]
}
sum
}
data$sum <- csum(data$value)
})
profvis({
csum2 <- function(x) {
if (length(x) < 2) return(x)
sum <- numeric(length(x))  # Preallocate
sum[1] <- x[1]
for (i in seq(2, length(x))) {
sum[i] <- sum[i-1] + x[i]
}
sum
}
data$sum <- csum2(data$value)
})
profvis({
runExample(example = "06_tabsets", display.mode = "normal")
})
profvis({
runExample(example = "06_tabsets", display.mode = "normal")
})
getwd()
library(shiny)
runApp("drinkr/shiny_app")
setwd("~/GitHub/Shiny/ShinyTest")
runApp("drinkr/shiny_app")
library(shinytest)
recordTest("drinkr/shiny_app")
testApp("drinkr/shiny_app")
runExample(example = "06_tabsets", display.mode = "normal")
